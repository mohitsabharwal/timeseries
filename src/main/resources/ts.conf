application.name=timeseries
application.batch.milliseconds=20000
application.executors=2
application.executor.cores=2
application.executor.memory=2g
application.spark.conf.spark.streaming.kafka.maxRatePerPartition=1000000
input.delimiter="|"
input.field.names=[timestamp,rmtuser,symbol,pid,clienthost,clientlogin,clientid,dqapp,datasource,startdate,enddate,syscount,exectime]
input.field.types=[string,string,string,int,string,string,string,string,string,string,string,int,int]
timestamp.format=["yyyy-MM-dd HH:mm:ss.SSSSS","yyyy-MM-dd HH:mm:ss"]
kafka.group.id=group1
kafka.topics=[stocks,bonds]
kafka.brokers="mohitc5-1.gce.cloudera.com:9092,mohitc5-2.gce.cloudera.com:9092,mohitc5-3.gce.cloudera.com:9092"
kafka.encoding=string
parameter.auto.offset.reset=earliest
zk.connection="mohitc5-1.gce.cloudera.com:2181,mohitc5-2.gce.cloudera.com:2181,mohitc5-3.gce.cloudera.com:2181"
zk.field.names=[group_id,topic,partition,offset]
zk.field.types=[string,string,int,long]
zk.key.field.names=[group_id,topic,partition]
zk.znode.prefix="/timeseries"
zk.session.timeout.millis=1000
output.file="/tmp/foo"
